{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWBmhmCqCFpp"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "package_dir = \"../input/pretrained-models.pytorch-master/\"\n",
    "sys.path.insert(0, package_dir)\n",
    "import pretrainedmodels\n",
    "package_dir = '../input/early-stopping-pytorch'\n",
    "sys.path.append(package_dir)\n",
    "from pytorchtools import EarlyStopping\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from collections import Counter, OrderedDict\n",
    "import json\n",
    "import math\n",
    "import numbers\n",
    "import time\n",
    "import cv2\n",
    "import gc\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from tensorboardX import SummaryWriter\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pynverse import inversefunc\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# To have reproducible results and compare them\n",
    "seedValue = 2019\n",
    "np.random.seed(seedValue)\n",
    "torch.manual_seed(seedValue)\n",
    "os.environ['PYTHONHASHSEED'] = str(seedValue)\n",
    "torch.cuda.manual_seed(seedValue)\n",
    "torch.cuda.manual_seed_all(seedValue) \n",
    "#torch.backends.cudnn.deterministic = True  \n",
    "#torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Specify GPU usage\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5\" \n",
    "device_ids = [0,1]\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "def quadratic_kappa(y_hat, y, coef):\n",
    "    for pred in enumerate(y_hat):\n",
    "            if pred[1] < coef[0]:\n",
    "                y_hat[1] = 0\n",
    "            elif pred[1] >= coef[0] and pred[1] < coef[1]:\n",
    "                y_hat[1] = 1\n",
    "            elif pred[1] >= coef[1] and pred[1] < coef[2]:\n",
    "                y_hat[1] = 2\n",
    "            elif pred[1] >= coef[2] and pred[1] < coef[3]:\n",
    "                y_hat[1] = 3\n",
    "            else:\n",
    "                y_hat[1] = 4\n",
    "    if CLASSIFICATION:\n",
    "        return torch.tensor(cohen_kappa_score(y_hat, y, weights='quadratic'),device=device)\n",
    "    else:\n",
    "        return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device=device)\n",
    "\n",
    "# confusion matrix\n",
    "def plot_cmx(true, output):\n",
    "    labels = [0,1,2,3,4]\n",
    "    cmx = confusion_matrix(true, output,labels=labels)\n",
    "    plt.figure(figsize=(6,4)) \n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    sns.heatmap(cmx, annot = True)\n",
    "    plt.show()\n",
    "    \n",
    "# calculate scale from ratio\n",
    "inv = inversefunc(lambda x : (np.arcsin(2*x**2-1)+2*x*np.sqrt(1-x**2))/(2*x**2),domain=[0.7,1.0])\n",
    "\n",
    "# params\n",
    "PREPROCESS ='kernel'\n",
    "CLASSIFICATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image1(img,tol=7):\n",
    "    # 'tol' is tolerance\n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img \n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "def crop_out_black(img):\n",
    "    height, width = img.shape[1:]\n",
    "    black = img[:, :int(height/20), :int(width/20)].mean(dim=(1, 2))\n",
    "    rowmeans = img.mean(dim=1)\n",
    "    linemeans = img.mean(dim=2)\n",
    "    nonblack_rows = ((rowmeans - black[:, None]).max(dim=0)[0] > .02).nonzero()\n",
    "    nonblack_lines = ((linemeans - black[:, None]).max(dim=0)[0] > .02).nonzero()\n",
    "    try:\n",
    "        left, right = nonblack_rows[0].item(), nonblack_rows[-1].item()\n",
    "        upper, lower = nonblack_lines[0].item(), nonblack_lines[-1].item()\n",
    "        img = img[:, upper:lower, left:right]\n",
    "    except:\n",
    "        print('crop out black didnt work')\n",
    "    return img\n",
    "\n",
    "def center(img):\n",
    "    # crop such that the center of mass of non-black pixels is roughly in the center\n",
    "    _, height, width = img.shape\n",
    "    shapified = shapify_torch(img)[0, ...] #just take one of 3 channels\n",
    "    nonzero = (shapified).nonzero().to(torch.float)\n",
    "    center = nonzero.mean(dim = 0).to(torch.int)\n",
    "    if center[0] > height/2: #center too low, crop from top\n",
    "        new_height = 2 * (height - center[0])\n",
    "        img = img[:, -new_height:, :]\n",
    "    else: #center too high, crop from bottom\n",
    "        new_height = 2 * center[0]\n",
    "        img = img[:, :new_height, :]\n",
    "    if center[1] > width/2: #center too far right, crop from left\n",
    "        new_width = 2*(width- center[1])\n",
    "        img = img[:, :, -new_width:]\n",
    "    else: #center too far left, crop from right\n",
    "        new_width = 2*center[1]\n",
    "        img = img[:, :, :new_width]\n",
    "    return img\n",
    "\n",
    "def tight_crop(img): #assumes black cropped out and centered\n",
    "    shapified = shapify_torch(img)[0, ...]\n",
    "    if shapified.to(torch.float).mean() > .95: #already tight crop\n",
    "        #print('already tight crop, passing')\n",
    "        return img\n",
    "    width = img.shape[2]\n",
    "    width_margin = int(.06 * width)\n",
    "    img = img[:, :, width_margin:-width_margin]\n",
    "    shapified = shapified[ :, width_margin:-width_margin]\n",
    "    num_white_per_line = shapified.sum(dim=1) / shapified.shape[1]\n",
    "    white_above_threshold = (num_white_per_line > .9).nonzero()\n",
    "    try:\n",
    "        upper, lower = white_above_threshold[0], white_above_threshold[-1]\n",
    "    except:\n",
    "        # image is too dark so that we crop out everything,\n",
    "        upper , lower = 0, img.shape[1]\n",
    "    img = img[:, upper:lower, :]\n",
    "    return img\n",
    "\n",
    "def shapify_torch(img_data):\n",
    "    height, width = img_data.shape[1:]\n",
    "    black = img_data[:, :int(height/20), :int(width/20)].mean(dim=(1, 2)) # get average r, g, b of top-left corner as an estimate for black value\n",
    "    mask = ((img_data - black[:, None, None]).max(dim = 0)[0] > .02).to(img_data.dtype) #note torch's max with argument dim returns (max, argmax)\n",
    "    return torch.stack((mask, mask, mask))\n",
    "\n",
    "to_256_torch = lambda img: torch.nn.functional.interpolate(img[None, ...], size = (256,256), \n",
    "                                                           mode='bilinear', align_corners = False)[0, ...]\n",
    "\n",
    "def remove_corners(img): #blacken a triangle of 1/6 at each corner. assumes square input\n",
    "    corner_size = img.shape[1]//6\n",
    "    mask = torch.ones( (corner_size, corner_size )).triu()\n",
    "    img[:, :corner_size, :corner_size] *= mask.flip(dims=(0,))[None, :, :]\n",
    "    img[:, :corner_size, -corner_size:] *= mask.flip(dims=(0,1))[None, :, :]\n",
    "    img[:, -corner_size:, :corner_size] *= mask[None, :, :]\n",
    "    img[:, -corner_size:, -corner_size:] *= mask.flip(dims=(1,))[None, :, :]\n",
    "    return(img)\n",
    "\n",
    "def gaussian_blur(img, radius=None, rel_size = None):\n",
    "    if radius is None:\n",
    "        radius = int(rel_size * img.shape[1])\n",
    "    if radius % 2 == 0:\n",
    "        radius = radius + 1\n",
    "    img_numpy = img.permute(1, 2, 0).numpy()\n",
    "    #img_numpy = cv2.GaussianBlur(img_numpy,(radius,radius),0)\n",
    "    img_numpy = cv2.GaussianBlur(img_numpy,(0,0),30)\n",
    "    img = torch.Tensor(img_numpy).permute(2, 0, 1)\n",
    "    return img\n",
    "\n",
    "def subtract_gaussian_blur(img, rel_size = .2, color_scale = 1):\n",
    "    img_blurred = gaussian_blur(img, rel_size = rel_size)\n",
    "    img = (4*color_scale*(img - img_blurred)).sigmoid() #sigmoid to squish to [0, 1]. Factor 4 because the slope of sigmoid at 0 is 4.\n",
    "    return img\n",
    "\n",
    "def zoom_to_center(img, tol=7, th = 0.90 ,p= 1.0):\n",
    "    img = crop_image_from_gray(img, tol = tol) \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    s1 = gray_img.size\n",
    "    mask = gray_img > 7\n",
    "    s2 = mask.sum()\n",
    "    # calculate Ratio of object to image\n",
    "    ratio = s2/s1\n",
    "    if ratio <= 0.95:\n",
    "        # The larger rest you have, the more a image is zoomed.\n",
    "        rest = np.sqrt(2)*inv(ratio)-1 if (ratio>= np.pi/4) else np.sqrt(2)-1\n",
    "        aug = albumentations.ShiftScaleRotate(shift_limit = 0.01, scale_limit=(rest-0.15, rest),\n",
    "                                              rotate_limit=5,p=0.7)\n",
    "        img = aug(image=img)['image']\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隣接したラベルを返すmixup用の関数\n",
    "# 例えば入力が0なら1を，2なら1or3を返す．\n",
    "def adj_label(self,l):\n",
    "    res = l - 1 + 2* np.random.randint(2)\n",
    "    if res == -1:\n",
    "        res = 1\n",
    "    elif res == 5:\n",
    "        res = 3\n",
    "    return res\n",
    "\n",
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform, datatype='train', mixup_prob=0):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.datatype = datatype\n",
    "        self.mixup_prob = mixup_prob\n",
    "        if CLASSIFICATION and mixup_prob>0:\n",
    "            print(\"mixup can't be used with classification\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # mixup is valid in datasets of 2015 or 2019 train\n",
    "        if self.datatype == 'test':\n",
    "            self.mixup_prob = 0\n",
    "            \n",
    "        # Whether to mixup or not is chosen with probability p\n",
    "        is_mixup = bool(np.random.binomial(n=1, p=self.mixup_prob)) \n",
    "        \n",
    "        # 画像データの読み込み\n",
    "        if self.datatype=='train':\n",
    "            img_name = os.path.join('../input/aptos2019-blindness-detection/train_images',\n",
    "                                self.data.loc[idx, 'id_code'] + '.png')\n",
    "            label = self.data.loc[idx, 'diagnosis']\n",
    "            if is_mixup:\n",
    "                label2 = adj_label(label)\n",
    "                img_id2 = self.data[self.data['diagnosis']==label2].sample(1).iloc[0]['id_code']\n",
    "                img_name2 = os.path.join('../input/aptos2019-blindness-detection/train_images',img_id2 + '.png')\n",
    "        elif self.datatype=='train_old':\n",
    "            img_name = os.path.join('../input/diabetic-retinopathy-resized/resized_train',\n",
    "                                self.data.loc[idx, 'image'] + '.jpeg')\n",
    "            label = self.data.loc[idx, 'level']\n",
    "            if is_mixup:\n",
    "                label2 = adj_label(label)\n",
    "                img_id2 = self.data[self.data['level']==label2].sample(1).iloc[0]['image']\n",
    "                img_name2 = os.path.join('../input/diabetic-retinopathy-resized/resized_train',img_id2 + '.jpeg')\n",
    "        else:\n",
    "            img_name =  os.path.join('../input/aptos2019-blindness-detection/test_images',\n",
    "                                     self.data.loc[idx, 'id_code'] + '.png')\n",
    "        # image preprocessing\n",
    "        img = self.image_process(img_name)\n",
    "        \n",
    "        # mix up two adjacent labeled images with probability mixup_prob\n",
    "        if is_mixup:\n",
    "            img2 = self.image_process(img_name2)\n",
    "            img = (img + img2['image']) / 2\n",
    "            label = (label + label2)/2 + np.random.normal(loc=0.0, scale=0.1**2)\n",
    "            \n",
    "        # batch must be a sequence of the same dtype,\n",
    "        # so all labels are float if mixup_prob is larger than 0.\n",
    "        if not self.datatype=='test':\n",
    "            if self.mixup_prob > 0:\n",
    "                label = torch.as_tensor(float(label))\n",
    "            elif not CLASSIFICATION:\n",
    "                label = torch.as_tensor(int(label))\n",
    "       \n",
    "        if self.datatype=='train':\n",
    "            return {'image': img,\n",
    "                    'labels': label\n",
    "                    }\n",
    "        elif self.datatype=='train_old':\n",
    "            return {'image': img,\n",
    "                    'labels': label\n",
    "                    }\n",
    "        else:\n",
    "            return {'image': img}\n",
    "        \n",
    "    def image_process(self,img_name):\n",
    "        if PREPROCESS=='kernel':\n",
    "            img = Image.open(img_name)\n",
    "        elif PREPROCESS=='original':\n",
    "            img = cv2.imread(img_name)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = zoom_to_center(img)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img = Image.fromarray(img)\n",
    "        \n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS == 'kernel':\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.ColorJitter(brightness=0.1,contrast=0,saturation=0),\n",
    "        transforms.ToTensor(),\n",
    "        crop_out_black, \n",
    "        center, \n",
    "        tight_crop, \n",
    "        to_256_torch, \n",
    "        remove_corners, \n",
    "        lambda img: subtract_gaussian_blur(img, rel_size=.2, color_scale=1), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "elif PREPROCESS=='original':\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0),\n",
    "        transforms.ToTensor(),\n",
    "        lambda img: subtract_gaussian_blur(img, rel_size=.2, color_scale=1), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True\n",
    "if PLOT:\n",
    "    rows = 4\n",
    "    cols = 10\n",
    "    data_dic = {\n",
    "                'train':{'csv':'../input/aptos2019-blindness-detection/train.csv','datatype':'train'},\n",
    "                'test':{'csv':'../input/aptos2019-blindness-detection/test.csv','datatype':'test'},\n",
    "                '2015':{'csv':'../input/diabetic-retinopathy-resized/new_trainLabels.csv','datatype':'train_old'},      \n",
    "               }\n",
    "    select = 'test'\n",
    "    sample_dataset = RetinopathyDataset(csv_file=data_dic[select]['csv'],\n",
    "                                        transform=transform, datatype=data_dic[select]['datatype'], mixup_prob=0)\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 16))\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = fig.add_subplot(5, 10, i * cols + j + 1, xticks=[], yticks=[])\n",
    "            data = sample_dataset.__getitem__(cols*i+j)\n",
    "            im =  data['image'].permute(1,2,0).numpy()\n",
    "            im = (im - np.amin(im)) / (np.amax(im) - np.amin(im)) *255\n",
    "            plt.imshow(im.astype(np.uint8))\n",
    "            if not select == 'test':\n",
    "                label = data['labels'].numpy()\n",
    "                ax.set_title('Label: {0:.2f}'.format(label))\n",
    "            if 10*i+j == 39:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "tuvwjkp7K-oa"
   },
   "outputs": [],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        if inputs.dim()>2:\n",
    "            inputs = inputs.view(inputs.size(0),inputs.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            inputs = inputs.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            inputs = inputs.contiguous().view(-1,inputs.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(inputs,dim=1)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = torch.autograd.Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=inputs.data.type():\n",
    "                self.alpha = self.alpha.type_as(inputs.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * torch.autograd.Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x\n",
    "    \n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self,sz=1):\n",
    "        super().__init__()\n",
    "        self.output_size = sz\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return torch.cat([self.mp(x),self.ap(x)],1)\n",
    "    \n",
    "def load_model_instagram():    \n",
    "    model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\n",
    "    for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Sequential(\n",
    "                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                          nn.Dropout(p=0.25),\n",
    "                          nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "                          nn.ReLU(),\n",
    "                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                          nn.Dropout(p=0.5),\n",
    "                          nn.Linear(in_features=2048, out_features=1, bias=True),\n",
    "                         )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_model_imagenet(pretrained='imagenet'):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super(Net, self).__init__()\n",
    "            for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "            if CLASSIFICATION:\n",
    "                #model.avgpool = AdaptiveConcatPool2d(1)\n",
    "                model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "                model.last_linear = nn.Sequential(\n",
    "                                                  Flatten(),\n",
    "                                                  nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), \n",
    "                                                  nn.Dropout(p=0.5),\n",
    "                                                  nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
    "                                                  nn.ReLU(),\n",
    "                                                  nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                                                  nn.Dropout(p=0.5),\n",
    "                                                  nn.Linear(in_features=1024, out_features=5, bias=True),\n",
    "                                                 )\n",
    "            else:\n",
    "                model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "                model.last_linear = nn.Sequential(\n",
    "                                                  nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                                                  nn.Dropout(p=0.25),\n",
    "                                                  nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "                                                  nn.ReLU(),\n",
    "                                                  nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                                                  nn.Dropout(p=0.5),\n",
    "                                                  nn.Linear(in_features=2048, out_features=1, bias=True),\n",
    "                                                 )\n",
    "            self.l1 = nn.Sequential(*list(model.children())[:-1]).to('cuda:0')\n",
    "            self.last = list(model.children())[-1]\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.l1(x)\n",
    "            x = x.view(x.size()[0], -1)\n",
    "            x = self.last(x)\n",
    "            return x\n",
    "\n",
    "    model = Net(pretrainedmodels.__dict__['resnet50'](pretrained=pretrained))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(object):\n",
    "    def __init__(self, params):\n",
    "        # params\n",
    "        self.lr = params.get('lr')\n",
    "        self.bs = params.get('batch_size')\n",
    "        self.n_epochs = params.get('n_epochs')\n",
    "        self.n_freeze = params.get('n_freeze')\n",
    "        self.coef = params.get('coef')\n",
    "        self.criterion = params.get('criterion')\n",
    "        self.num_workers = params.get('num_workers')\n",
    "        self.load_state = params.get('load_state')\n",
    "        self.load_path = params.get('load_path')\n",
    "        self.save_path = params.get('save_path')\n",
    "        self.device = params.get('device')\n",
    "        self.n_folds = params.get('n_folds')\n",
    "        self.use_valid = False\n",
    "        self.early_stop = params.get(\"early_stop\")\n",
    "        self.patience = params.get(\"patience\")\n",
    "        self.finetune = params.get(\"finetune\")\n",
    "        self.mixup_prob = params.get('mixup_prob')\n",
    "        self.is_mixup = bool(self.mixup_prob)\n",
    "    \n",
    "    def get_train(self,data):\n",
    "        self.train_data = data\n",
    "        \n",
    "    def get_valid(self,data):\n",
    "        self.valid_data = data\n",
    "        self.use_valid = True\n",
    "    \n",
    "    def fit(self, use_cv=False, train_idx=None, valid_idx=None):\n",
    "        since = time.time()\n",
    "        # Model\n",
    "        if self.load_state:\n",
    "            model = load_model_imagenet(pretrained='imagenet')\n",
    "            \n",
    "            # load params\n",
    "            if torch.cuda.device_count() > 1: # multi GPUs\n",
    "                state_dict = torch.load(self.load_path)\n",
    "                new_state_dict = OrderedDict()\n",
    "                for k, v in state_dict.items():\n",
    "                    name = k[7:] # remove `module.`\n",
    "                    new_state_dict[name] = v\n",
    "                model.load_state_dict(new_state_dict)\n",
    "            else:    \n",
    "                model.load_state_dict(torch.load(self.load_path, map_location=self.device))\n",
    "        else: # single GPU\n",
    "            model = load_model_imagenet(pretrained='imagenet')\n",
    "            \n",
    "        if torch.cuda.device_count() > 1: # train in parallel if multi GPUs available\n",
    "            model = nn.DataParallel(model, device_ids)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Set learning rate by layer, if you like\n",
    "        if torch.cuda.device_count() > 1: # multi GPUs \n",
    "            plist = [\n",
    "                     {'params': model.module.last.parameters(), 'lr': 1e-3}\n",
    "                    ]\n",
    "        else: # single GPU\n",
    "            plist = [\n",
    "                    {'params': model.last.parameters(), 'lr': 1e-3}\n",
    "                    ]\n",
    "\n",
    "        \n",
    "        optimizer = optim.Adam(plist, lr=self.lr)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=5)\n",
    "        \n",
    "        if use_cv: # if you choose cv, split the data into train and valid\n",
    "            train_sampler = SubsetRandomSampler(train_idx)\n",
    "            valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "            data_loader_train = torch.utils.data.DataLoader(self.train_data, batch_size=self.bs,\n",
    "                                                num_workers=self.num_workers,sampler=train_sampler)\n",
    "            data_loader_valid = torch.utils.data.DataLoader(self.train_data, batch_size=self.bs,\n",
    "                                                num_workers=self.num_workers,sampler=valid_sampler)\n",
    "            \n",
    "        # prepare train and valid data (e.g. train: 2015, valid: 2019)\n",
    "        elif self.use_valid:\n",
    "            data_loader_train = torch.utils.data.DataLoader(self.train_data, batch_size=self.bs,\n",
    "                                                num_workers=self.num_workers)\n",
    "            data_loader_valid = torch.utils.data.DataLoader(self.valid_data, batch_size=self.bs,\n",
    "                                                num_workers=self.num_workers)\n",
    "        else: # no validation\n",
    "            data_loader_train = torch.utils.data.DataLoader(self.train_data, batch_size=self.bs,\n",
    "                                                num_workers=self.num_workers)\n",
    "            \n",
    "        if self.early_stop: \n",
    "            early_stopping = EarlyStopping(patience=self.patience, verbose=True)\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            # unfreeze layers if you like\n",
    "            if epoch == self.n_freeze and not self.finetune:\n",
    "                if torch.cuda.device_count() > 1: # multi GPUs\n",
    "                    for param in model.module.parameters():\n",
    "                        param.requires_grad = True\n",
    "                else: # single GPU\n",
    "                    for param in model.parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "            print('Epoch {}/{}'.format(epoch, self.n_epochs - 1))\n",
    "            print('-' * 10)\n",
    "            scheduler.step()\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            kappa = 0\n",
    "            steps = 0\n",
    "            with tqdm(data_loader_train, total=int(len(data_loader_train))) as pbar:\n",
    "                for bi, d in enumerate(pbar):\n",
    "                    if CLASSIFICATION:\n",
    "                        inputs = d[\"image\"]\n",
    "                        labels = d[\"labels\"]\n",
    "                        inputs = inputs.to(device, dtype=torch.float)\n",
    "                        labels = labels.to(device, dtype=torch.long)\n",
    "                    else:\n",
    "                        inputs = d[\"image\"]\n",
    "                        labels = d[\"labels\"].view(-1, 1)\n",
    "                        inputs = inputs.to(self.device, dtype=torch.float)\n",
    "                        labels = labels.to(self.device, dtype=torch.float)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        outputs = model(inputs)\n",
    "                        loss =  self.criterion(outputs, labels)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.mean().item() \n",
    "                    if CLASSIFICATION:\n",
    "                        _,outputs =torch.max(outputs,1)\n",
    "                    # kappa is invalid if you use float labels\n",
    "                    if not self.is_mixup:\n",
    "                        y_hat = torch.Tensor.cpu(outputs.view(-1)).detach()\n",
    "                        y = torch.Tensor.cpu(labels.view(-1)).detach()\n",
    "                        kappa += quadratic_kappa(y_hat, y, self.coef).mean().item()\n",
    "                    steps += 1\n",
    "                    pbar.set_postfix(OrderedDict(rmse_loss = running_loss / steps,\n",
    "                                                 kappa_score = kappa / steps))\n",
    "                    \n",
    "            epoch_loss = running_loss / steps\n",
    "            print('Training Loss: {:.4f}'.format(epoch_loss))\n",
    "            # calculate kappa score only to monitor training\n",
    "            kappa = kappa / steps\n",
    "            print('Training Kappa: {:.4f}'.format(kappa))\n",
    "            \n",
    "            if self.use_valid or use_cv:\n",
    "                model.eval()\n",
    "                running_loss = 0.0\n",
    "                kappa = 0\n",
    "                steps = 0\n",
    "                true = np.zeros((len(self.valid_data), 1)) if not use_cv else np.zeros((len(valid_sampler), 1))\n",
    "                preds = np.zeros((len(self.valid_data), 1)) if not use_cv else np.zeros((len(valid_sampler), 1))\n",
    "\n",
    "                with tqdm(data_loader_valid , total=int(len(data_loader_valid))) as pbar:\n",
    "                    for step, batch in enumerate(pbar):\n",
    "                        if CLASSIFICATION:\n",
    "                            inputs = batch[\"image\"]\n",
    "                            labels = batch[\"labels\"]\n",
    "                            inputs = inputs.to(device, dtype=torch.float)\n",
    "                            labels = labels.to(device, dtype=torch.long)\n",
    "                        else:\n",
    "                            inputs = batch[\"image\"]\n",
    "                            labels = batch[\"labels\"].view(-1, 1)\n",
    "                            inputs = inputs.to(self.device, dtype=torch.float)\n",
    "                            labels = labels.to(self.device, dtype=torch.float)\n",
    "                            \n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(inputs)\n",
    "                            loss =  self.criterion(outputs, labels)\n",
    "\n",
    "                        running_loss += loss.mean().item()     \n",
    "                        \n",
    "                        if CLASSIFICATION:\n",
    "                            _,outputs =torch.max(outputs,1)\n",
    "                        # kappa is invalid if you use float labels\n",
    "                        if not self.is_mixup: \n",
    "                            y_hat = torch.Tensor.cpu(outputs.view(-1))\n",
    "                            y = torch.Tensor.cpu(labels.view(-1))\n",
    "                            true[step * self.bs:(step + 1) * self.bs] += labels.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n",
    "                            preds[step * self.bs:(step + 1) * self.bs] += outputs.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n",
    "                            kappa += quadratic_kappa(y_hat, y, self.coef).mean().item()\n",
    "                        steps += 1\n",
    "                        pbar.set_postfix(OrderedDict(rmse_loss = running_loss / steps,\n",
    "                                                     kappa_score = kappa / steps))\n",
    "                        \n",
    "                epoch_loss = running_loss / steps\n",
    "                print('Validation Loss: {:.4f}'.format(epoch_loss))\n",
    "                # calculate kappa score only to monitor training\n",
    "                kappa = kappa / steps\n",
    "                print('Validation Kappa: {:.4f}'.format(kappa))\n",
    "                plot_cmx(true.astype(int),preds.astype(int))\n",
    "                \n",
    "                # early stopping\n",
    "                if self.early_stop:\n",
    "                    eval_loss = epoch_loss\n",
    "                    early_stopping(eval_loss, model)\n",
    "                    if early_stopping.early_stop:\n",
    "                        print(\"Early stopping\")\n",
    "                        break\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        # save model except when cv\n",
    "        if not use_cv:\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "\n",
    "        del(model, data_loader_train)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() \n",
    "        \n",
    "    def cv(self): # cross validation\n",
    "        num_train = len(self.train_data)\n",
    "        indices = list(range(num_train))\n",
    "        kf = KFold(n_splits=self.n_folds, random_state=1337, shuffle=True)\n",
    "\n",
    "        train_idx = []\n",
    "        valid_idx = []\n",
    "\n",
    "        for t, v in kf.split(indices):\n",
    "            train_idx.append(t)\n",
    "            valid_idx.append(v)\n",
    "\n",
    "        # Training                        \n",
    "        for fold in np.arange(self.n_folds):\n",
    "            print('Fold:',fold)\n",
    "            self.fit(use_cv=True,train_idx=train_idx[fold],valid_idx=valid_idx[fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#params\n",
    "params = {\n",
    "    \"lr\" : 1e-5,\n",
    "    \"batch_size\" : 64,\n",
    "    \"n_epochs\" : 20,\n",
    "    \"n_freeze\" : 1,\n",
    "    \"num_workers\" : 10,\n",
    "    \"coef\" : [0.5, 1.5, 2.5, 3.5],\n",
    "    \"criterion\" :  FocalLoss() if CLASSIFICATION else RMSELoss,\n",
    "    \"load_state\" : False,\n",
    "    \"load_path\" : None, \n",
    "    'save_path' : None,\n",
    "    \"device\" : device,\n",
    "    \"n_folds\" : 5,\n",
    "    \"early_stop\" : True,\n",
    "    \"patience\" : 3,\n",
    "    \"finetune\" : False,\n",
    "    \"mixup_prob\" : 0,\n",
    "}\n",
    "\n",
    "#training for the lazy, like me\n",
    "\n",
    "# cv: new\n",
    "if 0:\n",
    "    params['finetune'] = True\n",
    "    params['load_state'] = True\n",
    "    #params['load_path'] =  \"../input/mmmodel/model_old_test.bin\" \n",
    "    params['load_path'] =  \"../data/checkpoint/checkpoint.pt\"\n",
    "    Mytrain = train(params)\n",
    "    Mytrain.get_train(RetinopathyDataset(csv_file=\"../input/aptos2019-blindness-detection/train.csv\",\n",
    "                                            transform=transform, datatype='train'))\n",
    "    Mytrain.cv()\n",
    "\n",
    "# train:old & valid:new\n",
    "if 1:\n",
    "    params['finetune'] = False\n",
    "    params['mixup_prob'] = 0\n",
    "    params['n_epochs'] = 40\n",
    "    params['patience'] = 4\n",
    "    params['save_path'] =  \"model_ResNet50_0821.bin\"\n",
    "    Mytrain = train(params)\n",
    "    Mytrain.get_train(RetinopathyDataset(csv_file=\"../input/diabetic-retinopathy-resized/new_trainLabels.csv\",\n",
    "                                            transform=transform, datatype='train_old',mixup_prob=params['mixup_prob']))\n",
    "    Mytrain.get_valid(RetinopathyDataset(csv_file=\"../input/aptos2019-blindness-detection/train.csv\",\n",
    "                                           transform=transform, datatype='train'))\n",
    "    Mytrain.fit()\n",
    "    \n",
    "# train:new\n",
    "if 1:\n",
    "    params['finetune'] = False\n",
    "    params['n_epochs'] = 4\n",
    "    params['load_state'] = True\n",
    "    #params['load_path'] =  \"../input/mmmodel/model_insta_old.bin\" \n",
    "    params['load_path'] =  \"checkpoint.pt\"\n",
    "    params['save_path'] =  \"model_ResNet50_0821.bin\"        \n",
    "    Mytrain = train(params)\n",
    "    Mytrain.get_train(RetinopathyDataset(csv_file=\"../input/aptos2019-blindness-detection/train.csv\",\n",
    "                                           transform=transform, datatype='train'))\n",
    "    Mytrain.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"../data/model/aptos19_ResNet101/model.bin\"\n",
    "\n",
    "model = load_model_instagram()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    state_dict = torch.load(load_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:    \n",
    "    model.load_state_dict(torch.load(load_path, map_location=self.device))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RetinopathyDataset(csv_file='../input/aptos2019-blindness-detection/sample_submission.csv',\n",
    "                                      transform=transform, datatype='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bM6q_rVj2hTR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_bs = 64\n",
    "test_preds = np.zeros((len(test_dataset), 1))\n",
    "TTA = 6\n",
    "for _ in range(TTA):\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_bs, shuffle=False, num_workers=8)\n",
    "    for i, x_batch in tqdm(enumerate(tqdm(test_data_loader))):\n",
    "        x_batch = x_batch[\"image\"]\n",
    "        pred = model(x_batch.to(device))\n",
    "        test_preds[i * test_bs:(i + 1) * test_bs] += pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n",
    "test_preds /= TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbGSxlHC2jpq"
   },
   "outputs": [],
   "source": [
    "coef = [0.5, 1.5, 2.5, 3.5]\n",
    "\n",
    "for i, pred in enumerate(test_preds):\n",
    "    if pred < coef[0]:\n",
    "        test_preds[i] = 0\n",
    "    elif pred >= coef[0] and pred < coef[1]:\n",
    "        test_preds[i] = 1\n",
    "    elif pred >= coef[1] and pred < coef[2]:\n",
    "        test_preds[i] = 2\n",
    "    elif pred >= coef[2] and pred < coef[3]:\n",
    "        test_preds[i] = 3\n",
    "    else:\n",
    "        test_preds[i] = 4\n",
    "\n",
    "\n",
    "sample = pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\n",
    "sample.diagnosis = test_preds.astype(int)\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "APTOS.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
