{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWBmhmCqCFpp"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "package_dir = \"../input/pretrained-models.pytorch-master/\"\n",
    "sys.path.insert(0, package_dir)\n",
    "import pretrainedmodels\n",
    "package_dir = '../input/early-stopping-pytorch'\n",
    "sys.path.append(package_dir)\n",
    "from pytorchtools import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter, OrderedDict\n",
    "import json\n",
    "import math\n",
    "import numbers\n",
    "import time\n",
    "import cv2\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "import gc\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import functional as F\n",
    "from albumentations.augmentations import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# To have reproducible results and compare them\n",
    "seedValue = 2019\n",
    "np.random.seed(seedValue)\n",
    "torch.manual_seed(seedValue)\n",
    "os.environ['PYTHONHASHSEED'] = str(seedValue)\n",
    "torch.cuda.manual_seed(seedValue)\n",
    "torch.cuda.manual_seed_all(seedValue) \n",
    "torch.backends.cudnn.deterministic = True  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Specify GPU usage\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5\" \n",
    "device_ids = [0,1]\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "def quadratic_kappa(y_hat, y, coef):\n",
    "    for pred in enumerate(y_hat):\n",
    "            if pred[1] < coef[0]:\n",
    "                y_hat[1] = 0\n",
    "            elif pred[1] >= coef[0] and pred[1] < coef[1]:\n",
    "                y_hat[1] = 1\n",
    "            elif pred[1] >= coef[1] and pred[1] < coef[2]:\n",
    "                y_hat[1] = 2\n",
    "            elif pred[1] >= coef[2] and pred[1] < coef[3]:\n",
    "                y_hat[1] = 3\n",
    "            else:\n",
    "                y_hat[1] = 4\n",
    "    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image1(img,tol=7):\n",
    "    # 'tol' is tolerance\n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img \n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        \n",
    "        return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([\n",
    "    albumentations.GaussianBlur(blur_limit=7,p=1),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.VerticalFlip(),\n",
    "    albumentations.RandomBrightness(limit=0.1),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    AT.ToTensor()\n",
    "    ])\n",
    "transform_valid_test = albumentations.Compose([\n",
    "    albumentations.GaussianBlur(blur_limit=7,p=1),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.VerticalFlip(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    AT.ToTensor()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform, datatype='train', mixup_prob=0):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.datatype = datatype\n",
    "        self.mixup_prob = mixup_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        is_mixup = bool(np.random.binomial(n=1, p=self.mixup_prob))\n",
    "        if self.datatype=='train':\n",
    "            img_name = os.path.join('../input/aptos2019-blindness-detection/train_images',\n",
    "                                self.data.loc[idx, 'id_code'] + '.png')\n",
    "            label = self.data.loc[idx, 'diagnosis']\n",
    "            if is_mixup:\n",
    "                label2 = self.adj_label(label)\n",
    "                img_id2 = self.data[self.data['diagnosis']==label2].sample(1).iloc[0]['id_code']\n",
    "                img_name2 = os.path.join('../input/aptos2019-blindness-detection/train_images',img_id2 + '.png')\n",
    "        elif self.datatype=='train_old':\n",
    "            img_name = os.path.join('../input/diabetic-retinopathy-resized/resized_train',\n",
    "                                self.data.loc[idx, 'image'] + '.jpeg')\n",
    "            label = self.data.loc[idx, 'level']\n",
    "            if is_mixup:\n",
    "                label2 = self.adj_label(label)\n",
    "                img_id2 = self.data[self.data['level']==label2].sample(1).iloc[0]['image']\n",
    "                img_name2 = os.path.join('../input/diabetic-retinopathy-resized/resized_train',img_id2 + '.jpeg')\n",
    "        else:\n",
    "            img_name =  os.path.join('../input/aptos2019-blindness-detection/test_images',\n",
    "                                     self.data.loc[idx, 'id_code'] + '.png')\n",
    "        img = self.image_process(img_name)\n",
    "        img = img['image']\n",
    "        if is_mixup:\n",
    "            img2 = self.image_process(img_name2)\n",
    "            img = (img + img2['image']) / 2\n",
    "            label = (label + label2)/2 + np.random.normal(loc=0.0, scale=0.1**2)\n",
    "        # batch must be a sequence of the same dtype\n",
    "        if self.mixup_prob > 0:\n",
    "            label = torch.as_tensor(float(label))\n",
    "        else:\n",
    "            label = torch.as_tensor(int(label))\n",
    "       \n",
    "        if self.datatype=='train':\n",
    "            return {'image': img,\n",
    "                    'labels': label\n",
    "                    }\n",
    "        elif self.datatype=='train_old':\n",
    "            return {'image': img,\n",
    "                    'labels': label\n",
    "                    }\n",
    "        else:\n",
    "            return {'image': img}\n",
    "        \n",
    "    def image_process(self,img_name):\n",
    "        img = cv2.imread(img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.zoom_to_center(img)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        # now replaced by albumentations func --> img = cv2.addWeighted (img,4, cv2.GaussianBlur(img,(0,0),30),-4,128)\n",
    "        img = self.transform(image=img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def zoom_to_center(self, img, tol=7, th = 0.90 ,p= 1.0):\n",
    "        img = crop_image_from_gray(img, tol = tol) \n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        s1 = gray_img.size\n",
    "        mask = gray_img > 7\n",
    "        s2 = mask.sum()\n",
    "        ratio = s2/s1\n",
    "        if ratio <= th:\n",
    "            coef = 1.1\n",
    "            # scale_limitのところはランダムに一様分布から選んでいるが，\n",
    "            # これは分布を考慮して後で修正する\n",
    "            # 閾値も修正予定\n",
    "            aug = albumentations.ShiftScaleRotate(shift_limit = 0.01, scale_limit=(0,coef-1),\n",
    "                                                  rotate_limit=15,p=p)\n",
    "            img = aug(image=img)['image']\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def adj_label(self,l):\n",
    "        res = l - 1 + 2* np.random.randint(2)\n",
    "        if res == -1:\n",
    "            res = 1\n",
    "        elif res == 5:\n",
    "            res = 3\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "if PLOT:\n",
    "    rows = 4\n",
    "    cols = 10\n",
    "    sample_dataset = RetinopathyDataset(csv_file=\"../input/aptos2019-blindness-detection/train.csv\",\n",
    "                                        transform=transform, datatype='train', mixup_prob=0.5)\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 16))\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = fig.add_subplot(5, 10, i * cols + j + 1, xticks=[], yticks=[])\n",
    "            data = sample_dataset.__getitem__(cols*i+j)\n",
    "            im =  data['image'].permute(1,2,0).numpy()\n",
    "            label = data['labels'].numpy()\n",
    "            im = (im - np.amin(im)) / (np.amax(im) - np.amin(im)) *255\n",
    "            plt.imshow(im.astype(np.uint8))\n",
    "            ax.set_title('Label: {0:.2f}'.format(label))\n",
    "            if 10*i+j == 39:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuvwjkp7K-oa"
   },
   "outputs": [],
   "source": [
    "def load_model_instagram():    \n",
    "    model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\n",
    "    for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Sequential(\n",
    "                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                          nn.Dropout(p=0.25),\n",
    "                          nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "                          nn.ReLU(),\n",
    "                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                          nn.Dropout(p=0.5),\n",
    "                          nn.Linear(in_features=2048, out_features=1, bias=True),\n",
    "                         )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_model_imagenet(pretrained='imagenet'):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super(Net, self).__init__()\n",
    "            for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "            model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "            model.last_linear = nn.Sequential(\n",
    "                                              nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                                              nn.Dropout(p=0.25),\n",
    "                                              nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "                                              nn.ReLU(),\n",
    "                                              nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                                              nn.Dropout(p=0.5),\n",
    "                                              nn.Linear(in_features=2048, out_features=1, bias=True),\n",
    "                                             )\n",
    "            self.l1 = nn.Sequential(*list(model.children())[:-1]).to('cuda:0')\n",
    "            self.last = list(model.children())[-1]\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.l1(x)\n",
    "            x = x.view(x.size()[0], -1)\n",
    "            x = self.last(x)\n",
    "            return x\n",
    "\n",
    "    model = Net(pretrainedmodels.__dict__['resnet50'](pretrained=pretrained))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(object):\n",
    "    def __init__(self, params):\n",
    "        self.lr = params.get('lr')\n",
    "        self.batch_size = params.get('batch_size')\n",
    "        self.n_epochs = params.get('n_epochs')\n",
    "        self.n_freeze = params.get('n_freeze')\n",
    "        self.coef = params.get('coef')\n",
    "        self.criterion = params.get('criterion')\n",
    "        self.num_workers = params.get('num_workers')\n",
    "        self.load_state = params.get('load_state')\n",
    "        self.load_path = params.get('load_path')\n",
    "        self.save_path = params.get('save_path')\n",
    "        self.device = params.get('device')\n",
    "        self.n_folds = params.get('n_folds')\n",
    "        self.use_valid = False\n",
    "        self.early_stop = params.get(\"early_stop\")\n",
    "        self.patience = params.get(\"patience\")\n",
    "        self.finetune = params.get(\"finetune\")\n",
    "        self.mixup_prob = params.get('mixup_prob')\n",
    "        self.is_mixup = bool(self.mixup_prob)\n",
    "    \n",
    "    def get_train(self,data):\n",
    "        self.train_data = data\n",
    "        \n",
    "    def get_valid(self,data):\n",
    "        self.valid_data = data\n",
    "        self.use_valid = True\n",
    "        \n",
    "    def fit(self, use_cv=False, train_idx=None, valid_idx=None):\n",
    "        since = time.time()\n",
    "        # Model\n",
    "        if self.load_state:\n",
    "            #model = load_model_instagram()\n",
    "            model = load_model_imagenet(pretrained='imagenet')\n",
    "            # load params\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                state_dict = torch.load(self.load_path)\n",
    "                new_state_dict = OrderedDict()\n",
    "                for k, v in state_dict.items():\n",
    "                    name = k[7:] # remove `module.`\n",
    "                    new_state_dict[name] = v\n",
    "                model.load_state_dict(new_state_dict)\n",
    "            else:    \n",
    "                model.load_state_dict(torch.load(self.load_path, map_location=self.device))\n",
    "        else:\n",
    "            #model = load_model_instagram()\n",
    "            model = load_model_imagenet(pretrained='imagenet')\n",
    "        if torch.cuda.device_count() > 1: \n",
    "            model = nn.DataParallel(model, device_ids)\n",
    "        model = model.to(device)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            plist = [\n",
    "                     #{'params': model.module.conv1.parameters(), 'lr': 1e-5, 'weight': 1e-4},\n",
    "                     #{'params': model.module.layer1.parameters(), 'lr': 2e-5, 'weight': 2e-4},\n",
    "                     #{'params': model.module.layer2.parameters(), 'lr': 3e-5, 'weight': 3e-4},\n",
    "                     #{'params': model.module.layer3.parameters(), 'lr': 5e-5, 'weight': 5e-4},\n",
    "                     #{'params': model.module.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n",
    "                     #{'params': model.module.fc.parameters(), 'lr': 1e-3}\n",
    "                     {'params': model.module.last.parameters(), 'lr': 1e-3}\n",
    "                    ]\n",
    "        else:\n",
    "            plist = [\n",
    "                     #{'params': model.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n",
    "                     #{'params': model.fc.parameters(), 'lr': 1e-3}\n",
    "                    {'params': model.last.parameters(), 'lr': 1e-3}\n",
    "                    ]\n",
    "\n",
    "        \n",
    "        optimizer = optim.Adam(plist, lr=self.lr)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=5)\n",
    "        \n",
    "        if use_cv:\n",
    "            train_sampler = SubsetRandomSampler(train_idx)\n",
    "            valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "            data_loader_train = torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size,\n",
    "                                                num_workers=self.num_workers,sampler=train_sampler)\n",
    "            data_loader_valid = torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size,\n",
    "                                                num_workers=self.num_workers,sampler=valid_sampler)\n",
    "        elif self.use_valid:\n",
    "            data_loader_train = torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size,\n",
    "                                                num_workers=self.num_workers)\n",
    "            data_loader_valid = torch.utils.data.DataLoader(self.valid_data, batch_size=self.batch_size,\n",
    "                                                num_workers=self.num_workers)\n",
    "        else:\n",
    "            data_loader_train = torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size,\n",
    "                                                num_workers=self.num_workers)\n",
    "            \n",
    "        if self.early_stop:\n",
    "            early_stopping = EarlyStopping(patience=self.patience, verbose=True)\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            if epoch == self.n_freeze and not self.finetune:\n",
    "                if torch.cuda.device_count() > 1:\n",
    "                    for param in model.module.parameters():\n",
    "                        param.requires_grad = True\n",
    "                else:\n",
    "                    for param in model.parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "            print('Epoch {}/{}'.format(epoch, self.n_epochs - 1))\n",
    "            print('-' * 10)\n",
    "            scheduler.step()\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            kappa = 0\n",
    "            steps = 0\n",
    "            with tqdm(data_loader_train, total=int(len(data_loader_train))) as pbar:\n",
    "                for bi, d in enumerate(pbar):\n",
    "                    inputs = d[\"image\"]\n",
    "                    labels = d[\"labels\"].view(-1, 1)\n",
    "                    inputs = inputs.to(self.device, dtype=torch.float)\n",
    "                    labels = labels.to(self.device, dtype=torch.float)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        outputs = model(inputs)\n",
    "                        loss =  torch.sqrt(self.criterion(outputs, labels)) #RMSE\n",
    "                        # <- insert custom mse\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.mean().item() \n",
    "                    y_hat = torch.Tensor.cpu(outputs.view(-1)).detach()\n",
    "                    y = torch.Tensor.cpu(labels.view(-1)).detach()\n",
    "                    if not self.is_mixup:\n",
    "                        kappa += quadratic_kappa(y_hat, y, self.coef).mean().item()\n",
    "                    steps += 1\n",
    "                    pbar.set_postfix(OrderedDict(rmse_loss = running_loss / steps,\n",
    "                                                 kappa_score = kappa / steps))\n",
    "                    \n",
    "            epoch_loss = running_loss / steps\n",
    "            print('Training Loss: {:.4f}'.format(epoch_loss))\n",
    "            if not self.is_mixup:\n",
    "                kappa = kappa / steps\n",
    "                print('Training Kappa: {:.4f}'.format(kappa))\n",
    "            \n",
    "            if self.use_valid or use_cv:\n",
    "                model.eval()\n",
    "                running_loss = 0.0\n",
    "                kappa = 0\n",
    "                steps = 0\n",
    "                \n",
    "                with tqdm(data_loader_valid , total=int(len(data_loader_valid))) as pbar:\n",
    "                    for step, batch in enumerate(pbar):\n",
    "                        inputs = batch[\"image\"]\n",
    "                        labels = batch[\"labels\"].view(-1, 1)\n",
    "                        inputs = inputs.to(self.device, dtype=torch.float)\n",
    "                        labels = labels.to(self.device, dtype=torch.float)\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(inputs)\n",
    "                            loss =  torch.sqrt(self.criterion(outputs, labels)) #RMSE\n",
    "\n",
    "                        running_loss += loss.mean().item()     \n",
    "                        y_hat = torch.Tensor.cpu(outputs.view(-1))\n",
    "                        y = torch.Tensor.cpu(labels.view(-1))\n",
    "                        if not self.is_mixup: kappa += quadratic_kappa(y_hat, y, self.coef).mean().item()\n",
    "                        steps += 1\n",
    "                        pbar.set_postfix(OrderedDict(rmse_loss = running_loss / steps,\n",
    "                                                     kappa_score = kappa / steps))\n",
    "                        \n",
    "                epoch_loss = running_loss / steps\n",
    "                print('Validation Loss: {:.4f}'.format(epoch_loss))\n",
    "                if not self.is_mixup:\n",
    "                    kappa = kappa / steps\n",
    "                    print('Validation Kappa: {:.4f}'.format(kappa))\n",
    "\n",
    "                if self.early_stop:\n",
    "                    eval_loss = epoch_loss\n",
    "                    early_stopping(eval_loss, model)\n",
    "                    if early_stopping.early_stop:\n",
    "                        print(\"Early stopping\")\n",
    "                        break\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        if not use_cv:\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "\n",
    "        del(model, data_loader_train)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() \n",
    "        \n",
    "    def cv(self):\n",
    "        num_train = len(self.train_data)\n",
    "        indices = list(range(num_train))\n",
    "        kf = KFold(n_splits=self.n_folds, random_state=1337, shuffle=True)\n",
    "\n",
    "        train_idx = []\n",
    "        valid_idx = []\n",
    "\n",
    "        for t, v in kf.split(indices):\n",
    "            train_idx.append(t)\n",
    "            valid_idx.append(v)\n",
    "\n",
    "        # Training                        \n",
    "        for fold in np.arange(self.n_folds):\n",
    "            print('Fold:',fold)\n",
    "            self.fit(use_cv=True,train_idx=train_idx[fold],valid_idx=valid_idx[fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#params\n",
    "params = {\n",
    "    \"lr\" : 1e-5,\n",
    "    \"batch_size\" : 64,\n",
    "    \"n_epochs\" : 20,\n",
    "    \"n_freeze\" : 1,\n",
    "    \"num_workers\" : 10,\n",
    "    \"coef\" : [0.5, 1.5, 2.5, 3.5],\n",
    "    \"criterion\" : nn.MSELoss(),\n",
    "    \"load_state\" : False,\n",
    "    \"load_path\" : None, \n",
    "    'save_path' : None,\n",
    "    \"device\" : device,\n",
    "    \"n_folds\" : 5,\n",
    "    \"early_stop\" : True,\n",
    "    \"patience\" : 3,\n",
    "    \"finetune\" : False,\n",
    "    \"mixup_prob\" : 0,\n",
    "}\n",
    "\n",
    "#training for the lazy, like me\n",
    "\n",
    "# cv: new\n",
    "if 0:\n",
    "    params['finetune'] = True\n",
    "    params['load_state'] = True\n",
    "    #params['load_path'] =  \"../input/mmmodel/model_old_test.bin\" \n",
    "    params['load_path'] =  \"../data/checkpoint/checkpoint.pt\"\n",
    "    Mytrain = train(params)\n",
    "    Mytrain.get_train(RetinopathyDataset(csv_file=\"../input/aptos2019-blindness-detection/train.csv\",\n",
    "                                            transform=transform, datatype='train'))\n",
    "    Mytrain.cv()\n",
    "\n",
    "# train:old & valid:new\n",
    "if 1:\n",
    "    params['finetune'] = False\n",
    "    params['mixup_prob'] = 0.5\n",
    "    params['n_epochs'] = 40\n",
    "    params['patience'] = 4\n",
    "    params['save_path'] =  \"model_ResNet50_old_mixup.bin\"\n",
    "    Mytrain = train(params)\n",
    "    Mytrain.get_train(RetinopathyDataset(csv_file=\"../input/diabetic-retinopathy-resized/new_trainLabels.csv\",\n",
    "                                            transform=transform, datatype='train_old',mixup_prob=params['mixup_prob']))\n",
    "    Mytrain.get_valid(RetinopathyDataset(csv_file=\"../input/aptos2019-blindness-detection/train.csv\",\n",
    "                                           transform=transform, datatype='train'))\n",
    "    Mytrain.fit()\n",
    "    \n",
    "# train:new\n",
    "if 0:\n",
    "    params['finetune'] = True\n",
    "    params['n_epochs'] = 3\n",
    "    params['load_state'] = True\n",
    "    #params['load_path'] =  \"../input/mmmodel/model_insta_old.bin\" \n",
    "    params['load_path'] =  \"checkpoint.pt\"\n",
    "    params['save_path'] =  \"model_ResNet50_old_mixup.bin\"        \n",
    "    Mytrain = train(params)\n",
    "    Mytrain.get_train(RetinopathyDataset(csv_file=\"../input/aptos2019-blindness-detection/train.csv\",\n",
    "                                           transform=transform, datatype='train'))\n",
    "    Mytrain.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"../data/model/aptos19_ResNet101/model.bin\"\n",
    "\n",
    "model = load_model_instagram()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    state_dict = torch.load(load_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:    \n",
    "    model.load_state_dict(torch.load(load_path, map_location=self.device))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RetinopathyDataset(csv_file='../input/aptos2019-blindness-detection/sample_submission.csv',\n",
    "                                      transform=transform_valid_test, datatype='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bM6q_rVj2hTR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_bs = 64\n",
    "test_preds = np.zeros((len(test_dataset), 1))\n",
    "TTA = 1\n",
    "for _ in range(TTA):\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_bs, shuffle=False, num_workers=8)\n",
    "    for i, x_batch in tqdm(enumerate(tqdm(test_data_loader))):\n",
    "        x_batch = x_batch[\"image\"]\n",
    "        pred = model(x_batch.to(device))\n",
    "        test_preds[i * test_bs:(i + 1) * test_bs] += pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n",
    "test_preds /= TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbGSxlHC2jpq"
   },
   "outputs": [],
   "source": [
    "coef = [0.5, 1.5, 2.5, 3.5]\n",
    "\n",
    "for i, pred in enumerate(test_preds):\n",
    "    if pred < coef[0]:\n",
    "        test_preds[i] = 0\n",
    "    elif pred >= coef[0] and pred < coef[1]:\n",
    "        test_preds[i] = 1\n",
    "    elif pred >= coef[1] and pred < coef[2]:\n",
    "        test_preds[i] = 2\n",
    "    elif pred >= coef[2] and pred < coef[3]:\n",
    "        test_preds[i] = 3\n",
    "    else:\n",
    "        test_preds[i] = 4\n",
    "\n",
    "\n",
    "sample = pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\n",
    "sample.diagnosis = test_preds.astype(int)\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"diagnosis\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "APTOS.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
